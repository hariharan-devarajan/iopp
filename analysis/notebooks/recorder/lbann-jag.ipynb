{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze lbann Jag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = \"lbann-jag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:44:28.361097Z",
     "start_time": "2021-09-16T21:44:28.356562Z"
    }
   },
   "outputs": [],
   "source": [
    "parquet_folder=\"/p/gpfs1/iopp/parquet_app_logs/lbann-jag/nodes-32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import os\n",
    "import time\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dask Cluster for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Job Queue Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/site-packages/dask_jobqueue/core.py:17: FutureWarning: format_bytes is deprecated and will be removed in a future release. Please use dask.utils.format_bytes instead.\n",
      "  from distributed.utils import format_bytes, parse_bytes, tmpfile, get_ip_interface\n",
      "/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/site-packages/dask_jobqueue/core.py:17: FutureWarning: parse_bytes is deprecated and will be removed in a future release. Please use dask.utils.parse_bytes instead.\n",
      "  from distributed.utils import format_bytes, parse_bytes, tmpfile, get_ip_interface\n",
      "/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/site-packages/dask_jobqueue/htcondor.py:6: FutureWarning: parse_bytes is deprecated and will be removed in a future release. Please use dask.utils.parse_bytes instead.\n",
      "  from distributed.utils import parse_bytes\n"
     ]
    }
   ],
   "source": [
    "import dask_jobqueue\n",
    "from dask_jobqueue import LSFCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Worker configuration\n",
    "When we use dask for analysis, we need to consider the type of analysis. In this case we plan to utilize dask dataframes for analysis that is typically memory intensive. Therefore, we allocate the whole memory per node and use only 4 worker processes per node. More worker processes reduce memory available per worker resulting in frequent memory swap from filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:00.088821Z",
     "start_time": "2021-09-16T21:37:00.076921Z"
    }
   },
   "outputs": [],
   "source": [
    "node_memory = 256 # node memory in GB\n",
    "n_workers_per_node = 4 # number of worker processes per node\n",
    "worker_time = \"06:00\" # job time per node for worker\n",
    "worker_queue = \"pbatch\" # queue to be used per worker\n",
    "n_workers = 32 # number of workers to be used for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other configurations we can compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = socket.gethostname()\n",
    "dashboard_address = '{}:8787'.format(socket.gethostname())\n",
    "memory = '{}GB'.format(node_memory/n_workers_per_node)\n",
    "job_extra = ['-nnodes 1', \n",
    "             '-G asccasc', \n",
    "             '-q {}'.format(worker_queue), \n",
    "             '-W {}'.format(worker_time), \n",
    "             '-o {}.log'.format(notebook_name), \n",
    "             '-e {}.log'.format(notebook_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dask Cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:00.580186Z",
     "start_time": "2021-09-16T21:37:00.574875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cls': <class 'distributed.scheduler.Scheduler'>, 'options': {'protocol': 'tcp://', 'interface': None, 'host': 'lassen708', 'dashboard_address': 'lassen708:8787', 'security': None}}\n",
      "Created Cluster with job script\n",
      " #!/usr/bin/env bash\n",
      "\n",
      "#BSUB -J dask-worker\n",
      "#BSUB -nnodes 1\n",
      "#BSUB -G asccasc\n",
      "#BSUB -q pbatch\n",
      "#BSUB -W 06:00\n",
      "#BSUB -o lbann-jag.log\n",
      "#BSUB -e lbann-jag.log\n",
      "JOB_ID=${LSB_JOBID%.*}\n",
      "\n",
      "/usr/workspace/iopp/.conda/envs/jupyter/bin/python -m distributed.cli.dask_worker tcp://192.168.66.200:46647 --nthreads 1 --nprocs 4 --memory-limit 59.60GiB --name name --nanny --death-timeout 60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/site-packages/distributed/node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 40147 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cluster = LSFCluster(cores = n_workers_per_node,processes=n_workers_per_node, memory='{}GB'.format(node_memory), \n",
    "                     header_skip=['-n ','-R','-M', '-P', '-W 00:30'], \n",
    "                     job_extra = job_extra, \n",
    "                     use_stdin=True, host = host,dashboard_address = dashboard_address)\n",
    "if cluster:\n",
    "    print(\"Created Cluster with job script\\n {}\".format(cluster.job_script()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Analysis Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.distributed import wait, progress\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dask Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-643c06e1-6032-11ec-97d7-70e28414902c</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.LSFCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://192.168.66.200:40147/status\" target=\"_blank\">http://192.168.66.200:40147/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LSFCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">97aede6d</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://192.168.66.200:40147/status\" target=\"_blank\">http://192.168.66.200:40147/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-f6b0991b-9dd7-4ab6-8dd4-4c65279f856c</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://192.168.66.200:46647\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://192.168.66.200:40147/status\" target=\"_blank\">http://192.168.66.200:40147/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://192.168.66.200:46647' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spawn cluster nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:00.937949Z",
     "start_time": "2021-09-16T21:37:00.931813Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for workers completed 2 of 32\n",
      "5 workers started\n"
     ]
    }
   ],
   "source": [
    "val = len(client.scheduler_info()[\"workers\"])\n",
    "while ((client.status == \"running\") and ( val < n_workers_per_node)):\n",
    "    print(\"Waiting for workers completed {} of {}\".format(val, n_workers), end=\"\\r\")\n",
    "    sleep(1.0)\n",
    "    val = len(client.scheduler_info()[\"workers\"])\n",
    "print(\"\\n{} workers started\".format(len(client.scheduler_info()[\"workers\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar()\n",
    "pbar.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:44:25.856496Z",
     "start_time": "2021-09-16T21:44:25.849113Z"
    }
   },
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        tic = time.perf_counter()\n",
    "        value = func(*args, **kwargs)\n",
    "        toc = time.perf_counter()\n",
    "        elapsed_time = toc - tic\n",
    "        print(f\"Elapsed time: {elapsed_time:0.4f} seconds\")\n",
    "        return value\n",
    "    return wrapper_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threading process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:44:26.580383Z",
     "start_time": "2021-09-16T21:44:26.570029Z"
    }
   },
   "outputs": [],
   "source": [
    "def thread_print(string):\n",
    "    print(f'{string}\\n', end='')\n",
    "def thread_process( num_ranks, func, start=0, list_range=[], workers=40):\n",
    "    with ThreadPoolExecutor(max_workers = workers) as executor:\n",
    "        if len(list_range) == 0:\n",
    "            list_range = range(start, num_ranks) \n",
    "        future_gen = {executor.submit(func, rank): rank for rank in list_range}\n",
    "        for future in concurrent.futures.as_completed(future_gen):\n",
    "            rank = future_gen[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "            except Exception as exc:\n",
    "                thread_print('%r generated an exception: %s' % (rank, exc))\n",
    "            else:\n",
    "                thread_print('%r data computed' % (rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Logs in Parquet format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Boostrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Application logs into dask dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:44:32.812813Z",
     "start_time": "2021-09-16T21:44:31.634540Z"
    }
   },
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(\"{}/*.parquet\".format(parquet_folder), engine=\"pyarrow-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:44:33.462433Z",
     "start_time": "2021-09-16T21:44:33.456132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask dataframe is split into 1031 partitions\n"
     ]
    }
   ],
   "source": [
    "print(\"Dask dataframe is split into {} partitions\".format(ddf.npartitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:12.311012Z",
     "start_time": "2021-09-16T21:37:12.306571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns present in dataset\n",
      "Index(['index', 'rank', 'thread_id', 'cat', 'tstart', 'tend', 'func_id',\n",
      "       'level', 'arg_count', 'args_1', 'args_2', 'args_3', 'args_4', 'args_5',\n",
      "       'args_6', 'args_7', 'args_8', 'args_9', 'args_10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns present in dataset\")\n",
    "print(ddf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:12.873991Z",
     "start_time": "2021-09-16T21:37:12.871121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rank</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>cat</th>\n",
       "      <th>tstart</th>\n",
       "      <th>tend</th>\n",
       "      <th>func_id</th>\n",
       "      <th>level</th>\n",
       "      <th>arg_count</th>\n",
       "      <th>args_1</th>\n",
       "      <th>args_2</th>\n",
       "      <th>args_3</th>\n",
       "      <th>args_4</th>\n",
       "      <th>args_5</th>\n",
       "      <th>args_6</th>\n",
       "      <th>args_7</th>\n",
       "      <th>args_8</th>\n",
       "      <th>args_9</th>\n",
       "      <th>args_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2127943504</td>\n",
       "      <td>2</td>\n",
       "      <td>0.178566</td>\n",
       "      <td>2.712372</td>\n",
       "      <td>MPI_Comm_dup</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>MPI_COMM_WORLD</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2127943504</td>\n",
       "      <td>2</td>\n",
       "      <td>2.712592</td>\n",
       "      <td>2.712593</td>\n",
       "      <td>MPI_Comm_rank</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-2127943504</td>\n",
       "      <td>2</td>\n",
       "      <td>2.712597</td>\n",
       "      <td>2.712597</td>\n",
       "      <td>MPI_Comm_size</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-0</td>\n",
       "      <td>128</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-2127943504</td>\n",
       "      <td>2</td>\n",
       "      <td>2.712606</td>\n",
       "      <td>2.713452</td>\n",
       "      <td>MPI_Comm_split_type</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>%p</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-2127943504</td>\n",
       "      <td>2</td>\n",
       "      <td>2.713541</td>\n",
       "      <td>2.713541</td>\n",
       "      <td>MPI_Comm_rank</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  rank   thread_id  cat    tstart      tend              func_id  \\\n",
       "0      1     0 -2127943504    2  0.178566  2.712372         MPI_Comm_dup   \n",
       "1      2     0 -2127943504    2  2.712592  2.712593        MPI_Comm_rank   \n",
       "2      3     0 -2127943504    2  2.712597  2.712597        MPI_Comm_size   \n",
       "3      4     0 -2127943504    2  2.712606  2.713452  MPI_Comm_split_type   \n",
       "4      5     0 -2127943504    2  2.713541  2.713541        MPI_Comm_rank   \n",
       "\n",
       "   level  arg_count          args_1 args_2 args_3 args_4 args_5 args_6 args_7  \\\n",
       "0      0          3  MPI_COMM_WORLD    0-0      0                               \n",
       "1      0          2             0-0      0                                      \n",
       "2      0          2             0-0    128                                      \n",
       "3      0          6             0-0      0      0     %p    0-1      0          \n",
       "4      0          2             0-1      0                                      \n",
       "\n",
       "  args_8 args_9 args_10  \n",
       "0                        \n",
       "1                        \n",
       "2                        \n",
       "3                        \n",
       "4                        "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only keep level zero from MPI and FTRACE but keep all levels for I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:13.310962Z",
     "start_time": "2021-09-16T21:37:13.306458Z"
    }
   },
   "outputs": [],
   "source": [
    "ddf = ddf[(ddf['level'] == 0) | ddf['cat'].isin([0,1,3])]\n",
    "#ddf = ddf.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataframe into I/O, MPI, and trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf = ddf[ddf['cat'].isin([0,1,3])]\n",
    "exclude_dirs = [\".pyc\", \"/usr\",\"/g/g92/haridev/.nccl.conf\"]\n",
    "for directory in exclude_dirs:\n",
    "    io_ddf = io_ddf[~io_ddf['args_1'].str.contains(directory)]\n",
    "#io_ddf[rank] = io_ddf[rank].persist()\n",
    "mpi_ddf = ddf[ddf['cat'] == 2]\n",
    "#mpi_ddf[rank] = mpi_ddf[rank].persist()\n",
    "trace_ddf = ddf[ddf['cat'] == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preload the I/O dataframe for faster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_22487/2462907219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mio_ddf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio_ddf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio_ddf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m   4241\u001b[0m     \"\"\"\n\u001b[1;32m   4242\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4243\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_when\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_when\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4244\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             return sync(\n\u001b[0m\u001b[1;32m    846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             )\n",
      "\u001b[0;32m/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "io_ddf = io_ddf.persist()\n",
    "result = wait(io_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check I/O interfaces used by application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interfaces = io_ddf['func_id'].unique().compute()\n",
    "print(interfaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "Only POSIX interface is used in this application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set duration of I/O events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf['duration'] = io_ddf['tend'] - io_ddf['tstart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negetive_duration = io_ddf[io_ddf['duration'] < 0]['duration'].count().compute()\n",
    "print(\"Application Profiler has stored {} negetive values\".format(negetive_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create conditions for filtering\n",
    "Even though this application doesnt have MPI or STDIO we have all the conditions here. This is to make sure we cover other apps as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_condition = io_ddf['func_id'].str.contains(\"open\")\n",
    "mpi_condition = io_ddf['func_id'].str.contains(\"MPI\")\n",
    "read_condition = io_ddf['func_id'].isin([\"read\", \"pread\", \"pread64\", \"readv\"])\n",
    "fread_condition = io_ddf['func_id'].isin([\"fread\"])\n",
    "close_condition = io_ddf['func_id'].str.contains('close')\n",
    "write_condition = io_ddf['func_id'].isin([\"write\", \"pwrite\", \"pwrite64\",\"writev\"])\n",
    "fwrite_condition = io_ddf['func_id'].isin([\"fwrite\"])\n",
    "readdir_condition = io_ddf['func_id'].isin([\"readdir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Filename from each row.\n",
    "This simplifies analysis later on as we can filter recorder per rank and per file to understand access pattern information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf['filename'] = \"\"\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(open_condition & ~mpi_condition, io_ddf['args_1'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(open_condition & mpi_condition, io_ddf['args_2'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(close_condition, io_ddf['args_1'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(read_condition, io_ddf['args_1'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(fread_condition, io_ddf['args_4'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(write_condition, io_ddf['args_1'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(fwrite_condition, io_ddf['args_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some filename has redundent forward slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf['filename'] = io_ddf['filename'].str.replace('//','/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter recorder which have read and write operations and which have metadata.\n",
    "We assume that there is only two types of operation in I/O read/write and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf_read_write = io_ddf[read_condition | write_condition].compute()\n",
    "io_ddf_metadata = io_ddf[~read_condition & ~write_condition].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build size and count to understand I/O on the io_ddf_read_write dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_condition = io_ddf_read_write['func_id'].str.contains(\"open\")\n",
    "mpi_condition = io_ddf_read_write['func_id'].str.contains(\"MPI\")\n",
    "read_condition = io_ddf_read_write['func_id'].isin([\"read\", \"pread\", \"pread64\", \"readv\"])\n",
    "fread_condition = io_ddf_read_write['func_id'].isin([\"fread\"])\n",
    "close_condition = io_ddf_read_write['func_id'].str.contains('close')\n",
    "write_condition = io_ddf_read_write['func_id'].isin([\"write\", \"pwrite\", \"pwrite64\",\"writev\"])\n",
    "fwrite_condition = io_ddf_read_write['func_id'].isin([\"fwrite\"])\n",
    "readdir_condition = io_ddf_read_write['func_id'].isin([\"readdir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf_read_write['size'] = 0\n",
    "io_ddf_read_write['count'] = 1\n",
    "io_ddf_read_write['size'] = io_ddf_read_write['size'].mask(read_condition , io_ddf_read_write['args_3'])\n",
    "io_ddf_read_write['size'] = io_ddf_read_write['size'].mask(fread_condition, io_ddf_read_write['args_3'])\n",
    "io_ddf_read_write['count'] = io_ddf_read_write['count'].mask(fread_condition, io_ddf_read_write['args_2'])\n",
    "io_ddf_read_write['size'] = io_ddf_read_write['size'].mask(write_condition, io_ddf_read_write['args_3'])\n",
    "io_ddf_read_write['size'] = io_ddf_read_write['size'].mask(fwrite_condition, io_ddf_read_write['args_3'])\n",
    "io_ddf_read_write['count'] = io_ddf_read_write['count'].mask(fwrite_condition, io_ddf_read_write['args_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corner cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf_read_write['size'] = io_ddf_read_write['size'].mask(readdir_condition , \"0\")\n",
    "io_ddf_read_write['count'] = io_ddf_read_write['count'].mask(readdir_condition , \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Datatypes\n",
    "This is needed as by default args are string from which they are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf_read_write = io_ddf_read_write.astype({'size': 'int32','count': 'int32'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Final Size\n",
    "After this point we do not use count field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf_read_write['size'] = io_ddf_read_write['size'] * io_ddf_read_write['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Bandwidth in MB/s for I/O operations.\n",
    "Durations might be incorrect or equal to zero due to profilers resolution issues. Therefore, we do bandwidth calculations for only correct durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_dur = ((io_ddf_read_write['tend'] - io_ddf_read_write['tstart']) > 0)\n",
    "io_ddf_read_write['bandwidth'] = 0\n",
    "io_ddf_read_write['bandwidth'] = io_ddf_read_write['bandwidth'].mask(correct_dur, io_ddf_read_write['size']*1.0/(io_ddf_read_write['tend'] - io_ddf_read_write['tstart'])/1024.0/1024.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "### Calculate all relevent filenames in the application\n",
    "The profiler might see jsrun files and other irrelevant internal files which we filter here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filenames = io_ddf[io_ddf['filename'].str.contains('/p/gpfs1')]['filename'].unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"The application accesses {} files across all ranks\".format(len(all_filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "### Distribution of Transfer Size and Bandwidth in the application\n",
    "The transfer size is given by the size column in bytes and the bandwidth is shown in MB/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "io_ddf_read_write[['size', 'bandwidth']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preload the I/O dataframe for faster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "io_ddf = io_ddf.persist()\n",
    "result = wait(io_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "## Application Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "num_ranks = io_ddf_read_write['rank'].nunique()\n",
    "print(\"Number of ranks in application {}\".format(num_ranks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total I/O amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "total_io = io_ddf_read_write.groupby('func_id')['size'].sum()/1024.0/1024.0/1024.0\n",
    "print(\"Total I/O in application {} GB\".format(total_io.sum()))\n",
    "print(\"Total I/O per operation in application {} GB\".format(total_io))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O per rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf_read_write.groupby(['rank', 'func_id'])['size'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**rank 0 performs 100x more I/O than others. Also every other process reads data where as only rank 0 writes it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_per_rank_gb = io_ddf_read_write.groupby(['rank'])['size'].sum()\n",
    "io_per_rank_gb.plot(kind='line',figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations Per Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_per_rank_gb = io_ddf_read_write.groupby('rank')['count'].sum()\n",
    "io_per_rank_gb.plot(kind='line',figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Also rank 0 performs 2000x more operations than other ranks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average I/O Time per process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_rank = io_ddf_read_write.groupby('rank')['duration'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"time per process: Average {} sec, Max {} sec, and Min {} sec\".format(time_per_rank.mean(), time_per_rank.max(), time_per_rank.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_rank.plot(kind='line',figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "Most time is spent by rank 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert trace dataframe into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_ddf_local = trace_ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate duration for trace values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_ddf_local['duration'] = trace_ddf_local['tend'] - trace_ddf_local['tstart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_ddf_local['duration'].describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "negetive_durations = trace_ddf_local[trace_ddf_local['duration'] < 0]['duration'].count().compute()\n",
    "print(\"Profiler stored {} negetive rows\".format(negetive_durations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_rank = trace_ddf_local.groupby('rank')['duration'].sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Time per process: Average {} sec, Max {} sec, and Min {} sec\".format(time_per_rank.mean(), time_per_rank.max(), time_per_rank.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_rank.plot(kind='line',figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No compute trace available**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_time = ddf['tend'].max().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Job Time in Application {} sec\".format(job_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The application run for a long time includes initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_compute = trace_ddf_local.groupby('rank')['duration'].sum().max().compute()\n",
    "total_io = io_ddf.groupby('rank')['duration'].sum().max().compute()\n",
    "print(\"I/O Time: {} sec Compute Time: {} sec\".format(total_io, total_compute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_intensity=total_io/(total_io + total_compute)\n",
    "comp_intensity=total_compute/(total_io + total_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I/O intensity: {}, Compute intensity: {}\".format(io_intensity, comp_intensity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**Application is not compute intensive as only 4 second of the overall time (i.e. 668 sec) is spent on I/O**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O Transfer Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df_temp = io_ddf_read_write\n",
    "size_ranges = [0, 4*1024, 64*1024, 1024*1024, 16*1024*1024]\n",
    "size_ranges_str = []\n",
    "for range_val in size_ranges:\n",
    "    size_ranges_str.append(str(range_val))\n",
    "max_range = len(size_ranges)\n",
    "request_size = [0]*len(size_ranges)\n",
    "for i, val in enumerate(size_ranges):\n",
    "    #print(i, max_range)\n",
    "    if i < max_range - 1:\n",
    "        request_size[i] = file_df_temp[(file_df_temp['size'].ge(val)) & \n",
    "                                       (file_df_temp['size'].lt(size_ranges[i+1]))]['size'].count()\n",
    "    else:\n",
    "        request_size[i] = file_df_temp[(file_df_temp['size'] >=size_ranges[i])]['size'].count()\n",
    "\n",
    "print(request_size)\n",
    "plt.bar(size_ranges_str, request_size)\n",
    "#file_sizes = file_df_temp['size'].to_numpy() / 1024.0 /1024.0\n",
    "#plt.hist(file_sizes, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application performs a lot of small I/O <=4 KB and reads 16MB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of request sizes per rank\n",
    "We need this as we see most I/O occurs by rank 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ranks = [0,1,2,3,4,5,6]\n",
    "for rank in selected_ranks:\n",
    "    file_df_temp = io_ddf_read_write[io_ddf_read_write['rank'] == rank]\n",
    "    size_ranges = [0, 4*1024, 64*1024, 1024*1024, 16*1024*1024]\n",
    "    size_ranges_str = []\n",
    "    for range_val in size_ranges:\n",
    "        size_ranges_str.append(str(range_val))\n",
    "    max_range = len(size_ranges)\n",
    "    request_size = [0]*len(size_ranges)\n",
    "    for i, val in enumerate(size_ranges):\n",
    "        #print(i, max_range)\n",
    "        if i < max_range - 1:\n",
    "            request_size[i] = file_df_temp[(file_df_temp['size'].ge(val)) & \n",
    "                                           (file_df_temp['size'].lt(size_ranges[i+1]))]['size'].count()\n",
    "        else:\n",
    "            request_size[i] = file_df_temp[(file_df_temp['size'] >=size_ranges[i])]['size'].count()\n",
    "\n",
    "    #print(request_size)\n",
    "    plt.bar(size_ranges_str, request_size)\n",
    "    #file_sizes = file_df_temp['size'].to_numpy() / 1024.0 /1024.0\n",
    "    #plt.hist(file_sizes, bins=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**The application uses a transfer size of 4K (used by rank 0) and 16MB (used by other ranks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Bandwidth achived by application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_ranges = [1, 128, 1024, 1024*64]\n",
    "bw_ranges_str = []\n",
    "for range_val in bw_ranges:\n",
    "    bw_ranges_str.append(str(range_val))\n",
    "max_range = len(bw_ranges)\n",
    "request_bw = [0]*len(bw_ranges)\n",
    "file_df_temp = io_ddf_read_write\n",
    "for i, val in enumerate(bw_ranges):\n",
    "    #print(i, max_range)\n",
    "    if i < max_range - 1:\n",
    "        request_bw[i] = file_df_temp[(file_df_temp['bandwidth'].ge(val)) & \n",
    "                                       (file_df_temp['bandwidth'].lt(bw_ranges[i+1]))]['size'].count()\n",
    "    else:\n",
    "        request_bw[i] = file_df_temp[(file_df_temp['bandwidth'] >=bw_ranges[i])]['size'].count()\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(bw_ranges_str, request_bw)\n",
    "for i, v in enumerate(request_bw):\n",
    "    ax.text(v + 3, i + .25, str(v), color='blue', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_bw = np.array(request_bw)*100/np.sum(request_bw)\n",
    "percentage_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "- 40% of the overall I/O got a bandwidth of 128 MB/s per process.\n",
    "- 35% achieve a low bandwidth of 64GB/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandwidth per request distribution\n",
    "We calculate the achived bandwidth per request size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = range(40)\n",
    "ranks_str = []\n",
    "for rank in ranks:\n",
    "    ranks_str.append(str(rank))\n",
    "size_ranges = [0, 4*1024, 64*1024, 1024*1024, 16*1024*1024]\n",
    "request_size = [[]]*len(size_ranges)\n",
    "for i, val in enumerate(size_ranges):\n",
    "    request_size[i] = [0]*len(ranks)\n",
    "    for j,rank in enumerate(ranks):\n",
    "        \n",
    "        file_df_temp = io_ddf_read_write[io_ddf_read_write['rank'] == rank]\n",
    "        max_range = len(size_ranges)\n",
    "        if i < max_range - 1:\n",
    "            request_size[i][j] = file_df_temp[(file_df_temp['size'].ge(val)) & \n",
    "                                           (file_df_temp['size'].lt(size_ranges[i+1]))]['bandwidth'].mean()\n",
    "        else:\n",
    "            request_size[i][j] = file_df_temp[(file_df_temp['size'] >=size_ranges[i])]['bandwidth'].mean()\n",
    "#fig, ax = plt.subplots(figsize=(16,4))\n",
    "#width = 0.35\n",
    "#plt.figure()\n",
    "for i, val in enumerate(size_ranges):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    print(np.sum(request_size[i]))\n",
    "    rects1 = plt.bar(ranks_str, request_size[i], 0.35, label=str(i))\n",
    "    plt.show()\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of files read/written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "all_filenames = io_ddf[io_ddf['filename'].str.contains('/p/gpfs1')]['filename'].unique().compute()\n",
    "print(\"The application accesses {} files\".format(len(all_filenames)))\n",
    "#print(all_filenames[:8],all_filenames[-8:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O Operations by Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf.groupby('func_id')['func_id'].count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As there are 1280 ranks in total, Most I/O is performed by rank 0 rest of them do less I/O**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IO Operations per rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf.groupby(['rank','func_id'])['func_id'].count().compute()[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf.groupby(['rank','func_id'])['func_id'].count().compute()[32:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**These confirm our hypothesis that most I/O is performed by rank 0 rest of them do less I/O**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandwidth per request distribution\n",
    "We calculate the achived bandwidth per request size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = range(40)\n",
    "ranks_str = []\n",
    "for rank in ranks:\n",
    "    ranks_str.append(str(rank))\n",
    "size_ranges = [0, 4*1024, 64*1024, 1024*1024, 16*1024*1024]\n",
    "request_size = [[]]*len(size_ranges)\n",
    "for i, val in enumerate(size_ranges):\n",
    "    request_size[i] = [0]*len(ranks)\n",
    "    for j,rank in enumerate(ranks):\n",
    "        \n",
    "        file_df_temp = io_ddf_read_write[io_ddf_read_write['rank'] == rank]\n",
    "        max_range = len(size_ranges)\n",
    "        if i < max_range - 1:\n",
    "            request_size[i][j] = file_df_temp[(file_df_temp['size'].ge(val)) & \n",
    "                                           (file_df_temp['size'].lt(size_ranges[i+1]))]['bandwidth'].mean()\n",
    "        else:\n",
    "            request_size[i][j] = file_df_temp[(file_df_temp['size'] >=size_ranges[i])]['bandwidth'].mean()\n",
    "#fig, ax = plt.subplots(figsize=(16,4))\n",
    "#width = 0.35\n",
    "#plt.figure()\n",
    "for i, val in enumerate(size_ranges):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    rects1 = plt.bar(ranks_str, request_size[i], 0.35, label=str(i))\n",
    "    plt.show()\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Larger Request sizes have larger bandwidth. However as 4KB write dominates the application I/O we see small bandwidth overall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlapping of Compute and I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf.groupby('rank')['thread_id'].nunique().describe().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No additional threads means I/O is synchronous to compute. I.e. all I/O is unoverlapped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeline\n",
    "The timeline analysis shows how each rank performs I/O over the runtime of the applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step=100000 # in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request Size Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "values = np.arange(0, math.ceil(job_time), time_step)\n",
    "values_int = range(len(values))\n",
    "values_str = []\n",
    "timeline_ts = [0]*len(values_int)\n",
    "prev = 0\n",
    "for i in values_int:\n",
    "    values_str.append(str(i))\n",
    "    contains = (io_ddf_read_write['tstart'] >=prev) & (io_ddf_read_write['tend'] <values[i])\n",
    "    timeline_ts[i] = io_ddf_read_write[contains]['size'].sum()/1024.0/1024.0\n",
    "    prev = i\n",
    "print(timeline_ts)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.bar(values_str, timeline_ts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**Most of the I/O (20GB) is performed in first 40 seconds and rest 1GB happens in the rest of the time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "values = np.arange(0, math.ceil(job_time), time_step)\n",
    "values_int = range(len(values))\n",
    "timeline_ts = [0]*len(values_int)\n",
    "prev = 0\n",
    "values_str = []\n",
    "for i in values_int:\n",
    "    values_str.append(str(i))\n",
    "    contains = (io_ddf_read_write['tstart'] >=prev) & (io_ddf_read_write['tend'] <values[i])\n",
    "    timeline_ts[i] = io_ddf_read_write[contains]['duration'].sum()\n",
    "    prev = i\n",
    "print(timeline_ts)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.bar(values_str, timeline_ts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bandwidth Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "values = np.arange(0, math.ceil(job_time), time_step)\n",
    "values_int = range(len(values))\n",
    "timeline_ts = [0]*len(values_int)\n",
    "prev = 0\n",
    "values_str = []\n",
    "for i in values_int:\n",
    "    values_str.append(str(i))\n",
    "    contains = (io_ddf_read_write['tstart'] >=prev) & (io_ddf_read_write['tend'] <values[i])\n",
    "    timeline_ts[i] = io_ddf_read_write[contains]['bandwidth'].mean()/10.0\n",
    "    prev = values[i]\n",
    "print(timeline_ts)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.bar(values_str, timeline_ts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This supports our previous observation as the bandwidth is the measure of I/O performance of the application.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bandwidth Timeline Per Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "selected_rank = [0, 4, 8, 12, 20]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "for rank in selected_rank:\n",
    "    io_df_rank = io_ddf_read_write[io_ddf_read_write['rank'] == rank]\n",
    "    values = np.arange(0, math.ceil(job_time), time_step)\n",
    "    values_int = range(len(values))\n",
    "    timeline_ts = [0]*len(values_int)\n",
    "    value_str = []\n",
    "    prev = 0\n",
    "    for i in values_int:\n",
    "        value_str.append(str(values[i]))\n",
    "        contains = (io_df_rank['tstart'] >=prev) & (io_df_rank['tend'] <values[i])\n",
    "        timeline_ts[i] = io_df_rank[contains]['bandwidth'].mean()\n",
    "        prev = values[i]\n",
    "    print(\"rank {}\".format(rank))\n",
    "    plt.bar(value_str, timeline_ts)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**Most I/O happens in the first 40 sec and most bandwidth is achieved from PFS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request Size Timeline per Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "selected_rank = [0, 4, 8, 12, 20]\n",
    "for rank in selected_rank:\n",
    "    io_df_rank = io_ddf_read_write[io_ddf_read_write['rank'] == rank]\n",
    "    values = np.arange(0, math.ceil(job_time), time_step)\n",
    "    values_int = range(len(values))\n",
    "    timeline_ts = [0]*len(values_int)\n",
    "    value_str = []\n",
    "    prev = 0\n",
    "    for i in values_int:\n",
    "        value_str.append(str(i))\n",
    "        contains = (io_df_rank['tstart'] >=prev) & (io_df_rank['tend'] <values[i])\n",
    "        timeline_ts[i] = io_df_rank[contains]['size'].sum()/1024.0/1024.0\n",
    "        prev = values[i]\n",
    "    print(\"rank {}\".format(rank))\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.bar(value_str, timeline_ts)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**Only rank 0 does I/O throughout the time. Rest perform read in first 40 seconds and perform computations.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find file which are independent or shared\n",
    "- Make all thread id start from 0 and unique across ranks\n",
    "- Group by filename nunique thread_id\n",
    "- Find all filename with nunique > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_index_series = io_ddf.groupby(['rank', 'thread_id'])['thread_id'].nunique().cumsum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf['thread_index'] = 0\n",
    "for index,item in thread_index_series.iteritems():\n",
    "    condition = (io_ddf['rank'] == index[0]) & (io_ddf['thread_id'] == index[1])\n",
    "    io_ddf['thread_index'] = io_ddf['thread_index'].mask(condition , item - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = io_ddf['thread_index'].nunique().compute()\n",
    "print(\"We have {} threads across {} ranks\".format(threads, num_ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_series = io_ddf[io_ddf['filename'].str.contains('/p/gpfs1')].groupby(['filename'])['thread_index'].nunique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "independent_files = filename_series[filename_series == 1]\n",
    "print(\"{} files that are accessed by application by only one rank\".format(len(independent_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "shared_files = filename_series[filename_series > 1]\n",
    "print(\"{} files that are accessed by application by more than one rank\".format(len(shared_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "This application doesnt share files. That is it follows a File per process pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Flow\n",
    "We plot how different ranks in the job are accessing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "selected_indices = range(1)\n",
    "for selected_index in selected_indices:\n",
    "    selected_shared_file = shared_files.index[selected_index]\n",
    "    io_access_rank = io_ddf[io_ddf['filename'] == selected_shared_file].groupby(['rank','func_id'])['func_id'].count().compute()\n",
    "    dot.node(selected_shared_file)\n",
    "    for index,item in io_access_rank.iteritems():\n",
    "        rank = index[0]\n",
    "        func_id = index[1]\n",
    "        count = item\n",
    "        dot.node(str(rank))\n",
    "        dot.node(func_id)\n",
    "        dot.edge(str(rank),func_id)\n",
    "        if \"read\" in func_id:\n",
    "            dot.edge(selected_shared_file, func_id, label=str(count))\n",
    "        else:\n",
    "            dot.edge(func_id,selected_shared_file, label=str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "selected_indices = [0]\n",
    "for selected_index in selected_indices:\n",
    "    if len(independent_files) > selected_index:\n",
    "        selected_file = independent_files.index[selected_index]\n",
    "        io_access_rank = io_ddf[io_ddf['filename'] == selected_file].groupby(['rank','func_id'])['func_id'].count().compute()\n",
    "        dot.node(selected_file)\n",
    "        for index,item in io_access_rank.iteritems():\n",
    "            rank = index[0]\n",
    "            func_id = index[1]\n",
    "            count = item\n",
    "            dot.node(str(rank))\n",
    "            dot.node(func_id)\n",
    "            dot.edge(str(rank),func_id)\n",
    "            if \"read\" in func_id:\n",
    "                dot.edge(selected_file, func_id, label=str(count))\n",
    "            else:\n",
    "                dot.edge(func_id,selected_file, label=str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Access Pattern\n",
    "- Calculate segment_index\n",
    "  - select file_ptr based on open flag\n",
    "  - update file_ptr based on operation\n",
    "  - do a cum_sum on file_ptr to calculate final file_ptr\n",
    "  - assign segment_index based on granularity (median transfer size)\n",
    "- isolate segment index into\n",
    "  - sequential flag if segment index is increasing\n",
    "  - consequitive flag if segment index is increasing and one after the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persist the current version of I/O dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "io_ddf = io_ddf.persist()\n",
    "result = wait(io_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select files which have no seeks and those which have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_with_seek = io_ddf[io_ddf['func_id'].str.contains('seek') & io_ddf['filename'].str.contains('/p/gpfs')]['filename'].unique().compute()\n",
    "print(\"{} files have seek operations\".format(len(files_with_seek)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_with_seek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_without_seek = set(all_filenames) - set(files_with_seek)\n",
    "print(\"{} files have no seek operations and hence are sequential\".format(len(files_without_seek)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Per File Analysis\n",
    "- Total I/O amount\n",
    "- Total I/O time (average per process)\n",
    "- Average Bandwidth\n",
    "- I/O Request Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_file_size = io_ddf_read_write.groupby(['filename'])['size'].sum()\n",
    "per_file_size = per_file_size / 1024.0/1024.0\n",
    "per_file_size = per_file_size.sort_values(ascending=False)\n",
    "per_file_size.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_file_time = io_ddf_read_write.groupby(['filename'])['duration'].sum().sort_values(ascending=False)\n",
    "per_file_time.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_file_bw = io_ddf_read_write.groupby(['filename'])['bandwidth'].sum().sort_values(ascending=True)\n",
    "per_file_bw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "selected_indices = [0]\n",
    "for selected_index in selected_indices:\n",
    "    selected_file = per_file_size.index[selected_index]\n",
    "    io_access_rank = io_ddf[io_ddf['filename'] == selected_file].groupby(['rank','func_id'])['func_id'].count().compute()\n",
    "    dot.node(selected_file)\n",
    "    for index,item in io_access_rank.iteritems():\n",
    "        rank = index[0]\n",
    "        func_id = index[1]\n",
    "        count = item\n",
    "        if \"read\" in func_id or \"write\" in func_id:\n",
    "            dot.node(str(rank))\n",
    "            dot.node(func_id)\n",
    "            dot.edge(str(rank),func_id)\n",
    "            if \"read\" in func_id:\n",
    "                dot.edge(selected_file, func_id, label=str(count))\n",
    "            elif \"write\" in func_id:\n",
    "                dot.edge(func_id,selected_file, label=str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "selected_indices = [0]\n",
    "for selected_index in selected_indices:\n",
    "    selected_file = per_file_time.index[selected_index]\n",
    "    io_access_rank = io_ddf[io_ddf['filename'] == selected_file].groupby(['rank','func_id'])['func_id'].count().compute()\n",
    "    dot.node(selected_file)\n",
    "    for index,item in io_access_rank.iteritems():\n",
    "        rank = index[0]\n",
    "        func_id = index[1]\n",
    "        count = item\n",
    "        dot.node(str(rank))\n",
    "        dot.node(func_id)\n",
    "        dot.edge(str(rank),func_id)\n",
    "        if \"read\" in func_id:\n",
    "            dot.edge(selected_file, func_id, label=str(count))\n",
    "        else:\n",
    "            dot.edge(func_id,selected_file, label=str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "selected_indices = range(5)\n",
    "for selected_index in selected_indices:\n",
    "    if len(per_file_bw) > selected_index:\n",
    "        selected_file = per_file_bw.index[selected_index]\n",
    "        io_access_rank = io_ddf[io_ddf['filename'] == selected_file].groupby(['rank','func_id'])['func_id'].count().compute()\n",
    "        dot.node(selected_file)\n",
    "        for index,item in io_access_rank.iteritems():\n",
    "            rank = index[0]\n",
    "            func_id = index[1]\n",
    "            count = item\n",
    "            dot.node(str(rank))\n",
    "            dot.node(func_id)\n",
    "            dot.edge(str(rank),func_id)\n",
    "            if \"read\" in func_id:\n",
    "                dot.edge(selected_file, func_id, label=str(count))\n",
    "            else:\n",
    "                dot.edge(func_id,selected_file, label=str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_files = io_ddf_read_write[io_ddf_read_write['func_id'].str.contains('write')]['filename'].unique()\n",
    "read_files = io_ddf_read_write[io_ddf_read_write['func_id'].str.contains('read')]['filename'].unique()\n",
    "read_only_files = set(all_filenames) - set(write_files)\n",
    "write_only_files = set(all_filenames) - set(read_files)\n",
    "print(\"{} files are written into.\\n{} file are read from.\\n{} files are write-only.\\n{} file are read-only.\"\n",
    "      .format(len(write_files), len(read_files), len(write_only_files), len(read_only_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in read_files:\n",
    "    file_size = os.path.getsize(file)\n",
    "    print(\"{} file has size {} bytes.\".format(file, file_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_condition = io_ddf['func_id'].isin([\"read\", \"pread\", \"pread64\", \"readv\",\"fread\"])\n",
    "write_condition = io_ddf['func_id'].isin([\"write\", \"pwrite\", \"pwrite64\",\"writev\",\"fwrite\"])\n",
    "data_ops = ['read', 'write']\n",
    "total_time_io_data = io_ddf[ read_condition | write_condition ].groupby('rank')['duration'].sum().max().compute()\n",
    "total_time_io_metadata = io_ddf[~(read_condition | write_condition)].groupby('rank')['duration'].sum().max().compute()\n",
    "print(\"Time spent on data: {} sec, metadata: {} sec\".format(total_time_io_data, total_time_io_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iopp",
   "language": "python",
   "name": "iopp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
