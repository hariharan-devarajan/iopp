{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Nek5000 workflow expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = \"nek5000-workflow-expansion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:44:28.361097Z",
     "start_time": "2021-09-16T21:44:28.356562Z"
    }
   },
   "outputs": [],
   "source": [
    "parquet_folder=\"/p/gpfs1/iopp/parquet_app_logs/nek5000/nodes-32/expansion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import os\n",
    "import time\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Dask Cluster for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Job Queue Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/site-packages/dask_jobqueue/core.py:17: FutureWarning: format_bytes is deprecated and will be removed in a future release. Please use dask.utils.format_bytes instead.\n",
      "  from distributed.utils import format_bytes, parse_bytes, tmpfile, get_ip_interface\n",
      "/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/site-packages/dask_jobqueue/core.py:17: FutureWarning: parse_bytes is deprecated and will be removed in a future release. Please use dask.utils.parse_bytes instead.\n",
      "  from distributed.utils import format_bytes, parse_bytes, tmpfile, get_ip_interface\n",
      "/usr/workspace/iopp/.conda/envs/jupyter/lib/python3.9/site-packages/dask_jobqueue/htcondor.py:6: FutureWarning: parse_bytes is deprecated and will be removed in a future release. Please use dask.utils.parse_bytes instead.\n",
      "  from distributed.utils import parse_bytes\n"
     ]
    }
   ],
   "source": [
    "import dask_jobqueue\n",
    "from dask_jobqueue import LSFCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Worker configuration\n",
    "When we use dask for analysis, we need to consider the type of analysis. In this case we plan to utilize dask dataframes for analysis that is typically memory intensive. Therefore, we allocate the whole memory per node and use only 4 worker processes per node. More worker processes reduce memory available per worker resulting in frequent memory swap from filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:00.088821Z",
     "start_time": "2021-09-16T21:37:00.076921Z"
    }
   },
   "outputs": [],
   "source": [
    "node_memory = 256 # node memory in GB\n",
    "n_workers_per_node = 4 # number of worker processes per node\n",
    "worker_time = \"02:00\" # job time per node for worker\n",
    "worker_queue = \"pdebug\" # queue to be used per worker\n",
    "n_workers = 16 # number of workers to be used for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other configurations we can compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = socket.gethostname()\n",
    "dashboard_address = '{}:8787'.format(socket.gethostname())\n",
    "memory = '{}GB'.format(node_memory/n_workers_per_node)\n",
    "job_extra = ['-nnodes 1', \n",
    "             '-G asccasc', \n",
    "             '-q {}'.format(worker_queue), \n",
    "             '-W {}'.format(worker_time), \n",
    "             '-o {}.log'.format(notebook_name), \n",
    "             '-e {}.log'.format(notebook_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dask Cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:00.580186Z",
     "start_time": "2021-09-16T21:37:00.574875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cls': <class 'distributed.scheduler.Scheduler'>, 'options': {'protocol': 'tcp://', 'interface': None, 'host': 'lassen709', 'dashboard_address': 'lassen709:8787', 'security': None}}\n",
      "Created Cluster with job script\n",
      " #!/usr/bin/env bash\n",
      "\n",
      "#BSUB -J dask-worker\n",
      "#BSUB -nnodes 1\n",
      "#BSUB -G asccasc\n",
      "#BSUB -q pdebug\n",
      "#BSUB -W 02:00\n",
      "#BSUB -o nek5000-workflow-expansion.log\n",
      "#BSUB -e nek5000-workflow-expansion.log\n",
      "JOB_ID=${LSB_JOBID%.*}\n",
      "\n",
      "/usr/workspace/iopp/.conda/envs/jupyter/bin/python -m distributed.cli.dask_worker tcp://192.168.66.201:45373 --nthreads 1 --nprocs 4 --memory-limit 59.60GiB --name name --nanny --death-timeout 60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster = LSFCluster(cores = n_workers_per_node,processes=n_workers_per_node, memory='{}GB'.format(node_memory), \n",
    "                     header_skip=['-n ','-R','-M', '-P', '-W 00:30'], \n",
    "                     job_extra = job_extra, \n",
    "                     use_stdin=True, host = host,dashboard_address = dashboard_address)\n",
    "if cluster:\n",
    "    print(\"Created Cluster with job script\\n {}\".format(cluster.job_script()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Analysis Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.distributed import wait, progress\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dask Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-fecfecbc-4348-11ec-8811-70e28414505f</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.LSFCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://192.168.66.201:8787/status\" target=\"_blank\">http://192.168.66.201:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LSFCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">0a90c525</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://192.168.66.201:8787/status\" target=\"_blank\">http://192.168.66.201:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-fe1d27b3-c3fc-42a6-9a1c-4c10a645048c</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://192.168.66.201:45373\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://192.168.66.201:8787/status\" target=\"_blank\">http://192.168.66.201:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://192.168.66.201:45373' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spawn cluster nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:00.937949Z",
     "start_time": "2021-09-16T21:37:00.931813Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 workers started\n"
     ]
    }
   ],
   "source": [
    "val = len(client.scheduler_info()[\"workers\"])\n",
    "while ((client.status == \"running\") and ( val > 8)):\n",
    "    print(\"Waiting for workers completed {} of {}\".format(val, n_workers), end=\"\\r\")\n",
    "    sleep(1.0)\n",
    "    val = len(client.scheduler_info()[\"workers\"])\n",
    "print(\"\\n{} workers started\".format(len(client.scheduler_info()[\"workers\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar()\n",
    "pbar.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:44:25.856496Z",
     "start_time": "2021-09-16T21:44:25.849113Z"
    }
   },
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        tic = time.perf_counter()\n",
    "        value = func(*args, **kwargs)\n",
    "        toc = time.perf_counter()\n",
    "        elapsed_time = toc - tic\n",
    "        print(f\"Elapsed time: {elapsed_time:0.4f} seconds\")\n",
    "        return value\n",
    "    return wrapper_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threading process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:44:26.580383Z",
     "start_time": "2021-09-16T21:44:26.570029Z"
    }
   },
   "outputs": [],
   "source": [
    "def thread_print(string):\n",
    "    print(f'{string}\\n', end='')\n",
    "def thread_process( num_ranks, func, start=0, list_range=[], workers=40):\n",
    "    with ThreadPoolExecutor(max_workers = workers) as executor:\n",
    "        if len(list_range) == 0:\n",
    "            list_range = range(start, num_ranks) \n",
    "        future_gen = {executor.submit(func, rank): rank for rank in list_range}\n",
    "        for future in concurrent.futures.as_completed(future_gen):\n",
    "            rank = future_gen[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "            except Exception as exc:\n",
    "                thread_print('%r generated an exception: %s' % (rank, exc))\n",
    "            else:\n",
    "                thread_print('%r data computed' % (rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Logs in Parquet format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Boostrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Application logs into dask dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:44:32.812813Z",
     "start_time": "2021-09-16T21:44:31.634540Z"
    }
   },
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet(\"{}/*.parquet\".format(parquet_folder), engine=\"pyarrow-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:44:33.462433Z",
     "start_time": "2021-09-16T21:44:33.456132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask dataframe is split into 160 partitions\n"
     ]
    }
   ],
   "source": [
    "print(\"Dask dataframe is split into {} partitions\".format(ddf.npartitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:12.311012Z",
     "start_time": "2021-09-16T21:37:12.306571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns present in dataset\n",
      "Index(['index', 'rank', 'thread_id', 'cat', 'tstart', 'tend', 'func_id',\n",
      "       'level', 'arg_count', 'args_1', 'args_2', 'args_3', 'args_4', 'args_5',\n",
      "       'args_6', 'args_7', 'args_8', 'args_9', 'args_10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns present in dataset\")\n",
    "print(ddf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:12.873991Z",
     "start_time": "2021-09-16T21:37:12.871121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rank</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>cat</th>\n",
       "      <th>tstart</th>\n",
       "      <th>tend</th>\n",
       "      <th>func_id</th>\n",
       "      <th>level</th>\n",
       "      <th>arg_count</th>\n",
       "      <th>args_1</th>\n",
       "      <th>args_2</th>\n",
       "      <th>args_3</th>\n",
       "      <th>args_4</th>\n",
       "      <th>args_5</th>\n",
       "      <th>args_6</th>\n",
       "      <th>args_7</th>\n",
       "      <th>args_8</th>\n",
       "      <th>args_9</th>\n",
       "      <th>args_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>319040</td>\n",
       "      <td>0</td>\n",
       "      <td>2.854341</td>\n",
       "      <td>2.854346</td>\n",
       "      <td>__xstat</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>/usr/WS2/iopp/applications/Nek5000/run/expansi...</td>\n",
       "      <td>%p</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>319040</td>\n",
       "      <td>0</td>\n",
       "      <td>2.854374</td>\n",
       "      <td>2.854913</td>\n",
       "      <td>open</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>/usr/WS2/iopp/applications/Nek5000/run/expansi...</td>\n",
       "      <td>524290</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>319040</td>\n",
       "      <td>0</td>\n",
       "      <td>2.854958</td>\n",
       "      <td>2.854960</td>\n",
       "      <td>__fxstat</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>/usr/WS2/iopp/applications/Nek5000/run/expansi...</td>\n",
       "      <td>%p</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>319040</td>\n",
       "      <td>0</td>\n",
       "      <td>2.855109</td>\n",
       "      <td>2.855433</td>\n",
       "      <td>read</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>/usr/WS2/iopp/applications/Nek5000/run/expansi...</td>\n",
       "      <td>%p</td>\n",
       "      <td>8192</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>319040</td>\n",
       "      <td>0</td>\n",
       "      <td>2.855441</td>\n",
       "      <td>2.855443</td>\n",
       "      <td>read</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>/usr/WS2/iopp/applications/Nek5000/run/expansi...</td>\n",
       "      <td>%p</td>\n",
       "      <td>8192</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  rank  thread_id  cat    tstart      tend   func_id  level  \\\n",
       "0      1     0     319040    0  2.854341  2.854346   __xstat      0   \n",
       "1      2     0     319040    0  2.854374  2.854913      open      0   \n",
       "2      3     0     319040    0  2.854958  2.854960  __fxstat      0   \n",
       "3      4     0     319040    0  2.855109  2.855433      read      0   \n",
       "4      5     0     319040    0  2.855441  2.855443      read      0   \n",
       "\n",
       "   arg_count                                             args_1  \\\n",
       "0          3                                                  1   \n",
       "1          2  /usr/WS2/iopp/applications/Nek5000/run/expansi...   \n",
       "2          3                                                  1   \n",
       "3          3  /usr/WS2/iopp/applications/Nek5000/run/expansi...   \n",
       "4          3  /usr/WS2/iopp/applications/Nek5000/run/expansi...   \n",
       "\n",
       "                                              args_2 args_3 args_4 args_5  \\\n",
       "0  /usr/WS2/iopp/applications/Nek5000/run/expansi...     %p                 \n",
       "1                                             524290                        \n",
       "2  /usr/WS2/iopp/applications/Nek5000/run/expansi...     %p                 \n",
       "3                                                 %p   8192                 \n",
       "4                                                 %p   8192                 \n",
       "\n",
       "  args_6 args_7 args_8 args_9 args_10  \n",
       "0                                      \n",
       "1                                      \n",
       "2                                      \n",
       "3                                      \n",
       "4                                      "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only keep level zero from MPI and FTRACE but keep all levels for I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-16T21:37:13.310962Z",
     "start_time": "2021-09-16T21:37:13.306458Z"
    }
   },
   "outputs": [],
   "source": [
    "ddf = ddf[(ddf['level'] == 0) | ddf['cat'].isin([0,1,3])]\n",
    "#ddf = ddf.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataframe into I/O, MPI, and trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf = ddf[ddf['cat'].isin([0,1,3])]\n",
    "exclude_dirs = [\".pyc\", \"/usr\",\"/g/g92/haridev/.nccl.conf\"]\n",
    "for directory in exclude_dirs:\n",
    "    io_ddf = io_ddf[~io_ddf['args_1'].str.contains(directory)]\n",
    "#io_ddf[rank] = io_ddf[rank].persist()\n",
    "mpi_ddf = ddf[ddf['cat'] == 2]\n",
    "#mpi_ddf[rank] = mpi_ddf[rank].persist()\n",
    "trace_ddf = ddf[ddf['cat'] == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preload the I/O dataframe for faster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "io_ddf = io_ddf.persist()\n",
    "result = wait(io_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check I/O interfaces used by application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      __xstat\n",
      "1     __fxstat\n",
      "2         open\n",
      "3    ftruncate\n",
      "4        close\n",
      "5       unlink\n",
      "6         read\n",
      "7        umask\n",
      "Name: func_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "interfaces = io_ddf['func_id'].unique().compute()\n",
    "print(interfaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "Only POSIX interface is used in this application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set duration of I/O events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf['duration'] = io_ddf['tend'] - io_ddf['tstart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application Profiler has stored 0 negetive values\n"
     ]
    }
   ],
   "source": [
    "negetive_duration = io_ddf[io_ddf['duration'] < 0]['duration'].count().compute()\n",
    "print(\"Application Profiler has stored {} negetive values\".format(negetive_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create conditions for filtering\n",
    "Even though this application doesnt have MPI or STDIO we have all the conditions here. This is to make sure we cover other apps as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_condition = io_ddf['func_id'].str.contains(\"open\")\n",
    "mpi_condition = io_ddf['func_id'].str.contains(\"MPI\")\n",
    "read_condition = io_ddf['func_id'].isin([\"read\", \"pread\", \"pread64\", \"readv\"])\n",
    "fread_condition = io_ddf['func_id'].isin([\"fread\"])\n",
    "close_condition = io_ddf['func_id'].str.contains('close')\n",
    "write_condition = io_ddf['func_id'].isin([\"write\", \"pwrite\", \"pwrite64\",\"writev\"])\n",
    "fwrite_condition = io_ddf['func_id'].isin([\"fwrite\"])\n",
    "readdir_condition = io_ddf['func_id'].isin([\"readdir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Filename from each row.\n",
    "This simplifies analysis later on as we can filter recorder per rank and per file to understand access pattern information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf['filename'] = \"\"\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(open_condition & ~mpi_condition, io_ddf['args_1'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(open_condition & mpi_condition, io_ddf['args_2'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(close_condition, io_ddf['args_1'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(read_condition, io_ddf['args_1'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(fread_condition, io_ddf['args_4'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(write_condition, io_ddf['args_1'])\n",
    "io_ddf['filename'] = io_ddf['filename'].mask(fwrite_condition, io_ddf['args_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some filename has redundent forward slashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf['filename'] = io_ddf['filename'].str.replace('//','/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter recorder which have read and write operations and which have metadata.\n",
    "We assume that there is only two types of operation in I/O read/write and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf_read_write = io_ddf[read_condition | write_condition].compute()\n",
    "io_ddf_metadata = io_ddf[~read_condition & ~write_condition].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build size and count to understand I/O on the io_ddf_read_write dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_condition = io_ddf_read_write['func_id'].str.contains(\"open\")\n",
    "mpi_condition = io_ddf_read_write['func_id'].str.contains(\"MPI\")\n",
    "read_condition = io_ddf_read_write['func_id'].isin([\"read\", \"pread\", \"pread64\", \"readv\"])\n",
    "fread_condition = io_ddf_read_write['func_id'].isin([\"fread\"])\n",
    "close_condition = io_ddf_read_write['func_id'].str.contains('close')\n",
    "write_condition = io_ddf_read_write['func_id'].isin([\"write\", \"pwrite\", \"pwrite64\",\"writev\"])\n",
    "fwrite_condition = io_ddf_read_write['func_id'].isin([\"fwrite\"])\n",
    "readdir_condition = io_ddf_read_write['func_id'].isin([\"readdir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf_read_write['size'] = 0\n",
    "io_ddf_read_write['count'] = 1\n",
    "io_ddf_read_write['size'] = io_ddf_read_write['size'].mask(read_condition , io_ddf_read_write['args_3'])\n",
    "io_ddf_read_write['size'] = io_ddf_read_write['size'].mask(fread_condition, io_ddf_read_write['args_3'])\n",
    "io_ddf_read_write['count'] = io_ddf_read_write['count'].mask(fread_condition, io_ddf_read_write['args_2'])\n",
    "io_ddf_read_write['size'] = io_ddf_read_write['size'].mask(write_condition, io_ddf_read_write['args_3'])\n",
    "io_ddf_read_write['size'] = io_ddf_read_write['size'].mask(fwrite_condition, io_ddf_read_write['args_3'])\n",
    "io_ddf_read_write['count'] = io_ddf_read_write['count'].mask(fwrite_condition, io_ddf_read_write['args_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corner cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf_read_write['size'] = io_ddf_read_write['size'].mask(readdir_condition , \"0\")\n",
    "io_ddf_read_write['count'] = io_ddf_read_write['count'].mask(readdir_condition , \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Datatypes\n",
    "This is needed as by default args are string from which they are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf_read_write = io_ddf_read_write.astype({'size': 'int32','count': 'int32'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Final Size\n",
    "After this point we do not use count field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf_read_write['size'] = io_ddf_read_write['size'] * io_ddf_read_write['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Bandwidth in MB/s for I/O operations.\n",
    "Durations might be incorrect or equal to zero due to profilers resolution issues. Therefore, we do bandwidth calculations for only correct durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_dur = ((io_ddf_read_write['tend'] - io_ddf_read_write['tstart']) > 0)\n",
    "io_ddf_read_write['bandwidth'] = 0\n",
    "io_ddf_read_write['bandwidth'] = io_ddf_read_write['bandwidth'].mask(correct_dur, io_ddf_read_write['size']*1.0/(io_ddf_read_write['tend'] - io_ddf_read_write['tstart'])/1024.0/1024.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "### Calculate all relevent filenames in the application\n",
    "The profiler might see jsrun files and other irrelevant internal files which we filter here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filenames = io_ddf[io_ddf['filename'].str.contains('/p/gpfs1')]['filename'].unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The application accesses 0 files across all ranks\n"
     ]
    }
   ],
   "source": [
    "print(\"The application accesses {} files across all ranks\".format(len(all_filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "### Distribution of Transfer Size and Bandwidth in the application\n",
    "The transfer size is given by the size column in bytes and the bandwidth is shown in MB/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>bandwidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         size  bandwidth\n",
       "count     1.0        1.0\n",
       "mean   4096.0        0.0\n",
       "std       NaN        NaN\n",
       "min    4096.0        0.0\n",
       "25%    4096.0        0.0\n",
       "50%    4096.0        0.0\n",
       "75%    4096.0        0.0\n",
       "max    4096.0        0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io_ddf_read_write[['size', 'bandwidth']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preload the I/O dataframe for faster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "io_ddf = io_ddf.persist()\n",
    "result = wait(io_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "## Application Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ranks in application 1\n"
     ]
    }
   ],
   "source": [
    "num_ranks = io_ddf_read_write['rank'].nunique()\n",
    "print(\"Number of ranks in application {}\".format(num_ranks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total I/O amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total I/O in application 3.814697265625e-06 GB\n",
      "Total I/O per operation in application func_id\n",
      "read    0.000004\n",
      "Name: size, dtype: float64 GB\n"
     ]
    }
   ],
   "source": [
    "total_io = io_ddf_read_write.groupby('func_id')['size'].sum()/1024.0/1024.0/1024.0\n",
    "print(\"Total I/O in application {} GB\".format(total_io.sum()))\n",
    "print(\"Total I/O per operation in application {} GB\".format(total_io))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O per rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank  func_id\n",
       "0     read       4096\n",
       "Name: size, dtype: int32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io_ddf_read_write.groupby(['rank', 'func_id'])['size'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**rank 0 performs 100x more I/O than others. Also every other process reads data where as only rank 0 writes it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='rank'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "io_per_rank_gb = io_ddf_read_write.groupby(['rank'])['size'].sum()\n",
    "io_per_rank_gb.plot(kind='line',figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations Per Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='rank'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "io_per_rank_gb = io_ddf_read_write.groupby('rank')['count'].sum()\n",
    "io_per_rank_gb.plot(kind='line',figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Also rank 0 performs 2000x more operations than other ranks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average I/O Time per process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_rank = io_ddf_read_write.groupby('rank')['duration'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time per process: Average 0.0 sec, Max 0.0 sec, and Min 0.0 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"time per process: Average {} sec, Max {} sec, and Min {} sec\".format(time_per_rank.mean(), time_per_rank.max(), time_per_rank.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='rank'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_per_rank.plot(kind='line',figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "Most time is spent by rank 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert trace dataframe into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_ddf_local = trace_ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate duration for trace values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_ddf_local['duration'] = trace_ddf_local['tend'] - trace_ddf_local['tstart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "    float64\n",
       "        ...\n",
       "Name: duration, dtype: float64\n",
       "Dask Name: describe-numeric, 3744 tasks"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_ddf_local['duration'].describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "negetive_durations = trace_ddf_local[trace_ddf_local['duration'] < 0]['duration'].count().compute()\n",
    "print(\"Profiler stored {} negetive rows\".format(negetive_durations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_rank = trace_ddf_local.groupby('rank')['duration'].sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Time per process: Average {} sec, Max {} sec, and Min {} sec\".format(time_per_rank.mean(), time_per_rank.max(), time_per_rank.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_rank.plot(kind='line',figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No compute trace available**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_time = ddf['tend'].max().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Job Time in Application {} sec\".format(job_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The application run for a long time includes initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_compute = trace_ddf_local.groupby('rank')['duration'].sum().max()\n",
    "total_io = io_ddf.groupby('rank')['duration'].sum().max().compute()\n",
    "print(\"I/O Time: {} sec Compute Time: {} sec\".format(total_io, total_compute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_intensity=total_io/(total_io + total_compute)\n",
    "comp_intensity=total_compute/(total_io + total_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I/O intensity: {}, Compute intensity: {}\".format(io_intensity, comp_intensity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**Application is not compute intensive as only 4 second of the overall time (i.e. 668 sec) is spent on I/O**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O Transfer Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df_temp = io_ddf_read_write\n",
    "size_ranges = [0, 4*1024, 64*1024, 1024*1024, 16*1024*1024]\n",
    "size_ranges_str = []\n",
    "for range_val in size_ranges:\n",
    "    size_ranges_str.append(str(range_val))\n",
    "max_range = len(size_ranges)\n",
    "request_size = [0]*len(size_ranges)\n",
    "for i, val in enumerate(size_ranges):\n",
    "    #print(i, max_range)\n",
    "    if i < max_range - 1:\n",
    "        request_size[i] = file_df_temp[(file_df_temp['size'].ge(val)) & \n",
    "                                       (file_df_temp['size'].lt(size_ranges[i+1]))]['size'].count()\n",
    "    else:\n",
    "        request_size[i] = file_df_temp[(file_df_temp['size'] >=size_ranges[i])]['size'].count()\n",
    "\n",
    "#print(request_size)\n",
    "plt.bar(size_ranges_str, request_size)\n",
    "#file_sizes = file_df_temp['size'].to_numpy() / 1024.0 /1024.0\n",
    "#plt.hist(file_sizes, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application performs a lot of small I/O <=4 KB and reads 16MB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of request sizes per rank\n",
    "We need this as we see most I/O occurs by rank 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ranks = [0,1,2,3,4,5,6]\n",
    "for rank in selected_ranks:\n",
    "    file_df_temp = io_ddf_read_write[io_ddf_read_write['rank'] == rank]\n",
    "    size_ranges = [0, 4*1024, 64*1024, 1024*1024, 16*1024*1024]\n",
    "    size_ranges_str = []\n",
    "    for range_val in size_ranges:\n",
    "        size_ranges_str.append(str(range_val))\n",
    "    max_range = len(size_ranges)\n",
    "    request_size = [0]*len(size_ranges)\n",
    "    for i, val in enumerate(size_ranges):\n",
    "        #print(i, max_range)\n",
    "        if i < max_range - 1:\n",
    "            request_size[i] = file_df_temp[(file_df_temp['size'].ge(val)) & \n",
    "                                           (file_df_temp['size'].lt(size_ranges[i+1]))]['size'].count()\n",
    "        else:\n",
    "            request_size[i] = file_df_temp[(file_df_temp['size'] >=size_ranges[i])]['size'].count()\n",
    "\n",
    "    #print(request_size)\n",
    "    plt.bar(size_ranges_str, request_size)\n",
    "    #file_sizes = file_df_temp['size'].to_numpy() / 1024.0 /1024.0\n",
    "    #plt.hist(file_sizes, bins=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**The application uses a transfer size of 4K (used by rank 0) and 16MB (used by other ranks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Bandwidth achived by application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_ranges = [1, 128, 1024, 1024*64]\n",
    "bw_ranges_str = []\n",
    "for range_val in bw_ranges:\n",
    "    bw_ranges_str.append(str(range_val))\n",
    "max_range = len(bw_ranges)\n",
    "request_bw = [0]*len(bw_ranges)\n",
    "for i, val in enumerate(bw_ranges):\n",
    "    #print(i, max_range)\n",
    "    if i < max_range - 1:\n",
    "        request_bw[i] = file_df_temp[(file_df_temp['bandwidth'].ge(val)) & \n",
    "                                       (file_df_temp['bandwidth'].lt(bw_ranges[i+1]))]['size'].count()\n",
    "    else:\n",
    "        request_bw[i] = file_df_temp[(file_df_temp['bandwidth'] >=bw_ranges[i])]['size'].count()\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(bw_ranges_str, request_bw)\n",
    "for i, v in enumerate(request_bw):\n",
    "    ax.text(v + 3, i + .25, str(v), color='blue', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_bw = np.array(request_bw)*100/np.sum(request_bw)\n",
    "percentage_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "- 40% of the overall I/O got a bandwidth of 128 MB/s per process.\n",
    "- 35% achieve a low bandwidth of 64GB/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of files read/written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "all_filenames = io_ddf[io_ddf['filename'].str.contains('/p/gpfs1')]['filename'].unique().compute()\n",
    "print(\"The application accesses {} files\".format(len(all_filenames)))\n",
    "#print(all_filenames[:8],all_filenames[-8:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O Operations by Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf.groupby('func_id')['func_id'].count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As there are 1280 ranks in total, Most I/O is performed by rank 0 rest of them do less I/O**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IO Operations per rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf.groupby(['rank','func_id'])['func_id'].count().compute()[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf.groupby(['rank','func_id'])['func_id'].count().compute()[32:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**These confirm our hypothesis that most I/O is performed by rank 0 rest of them do less I/O**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandwidth per request distribution\n",
    "We calculate the achived bandwidth per request size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = range(40)\n",
    "ranks_str = []\n",
    "for rank in ranks:\n",
    "    ranks_str.append(str(rank))\n",
    "size_ranges = [0, 4*1024, 64*1024, 1024*1024, 16*1024*1024]\n",
    "request_size = [[]]*len(size_ranges)\n",
    "for i, val in enumerate(size_ranges):\n",
    "    request_size[i] = [0]*len(ranks)\n",
    "    for j,rank in enumerate(ranks):\n",
    "        \n",
    "        file_df_temp = io_ddf_read_write[io_ddf_read_write['rank'] == rank]\n",
    "        max_range = len(size_ranges)\n",
    "        if i < max_range - 1:\n",
    "            request_size[i][j] = file_df_temp[(file_df_temp['size'].ge(val)) & \n",
    "                                           (file_df_temp['size'].lt(size_ranges[i+1]))]['bandwidth'].mean()\n",
    "        else:\n",
    "            request_size[i][j] = file_df_temp[(file_df_temp['size'] >=size_ranges[i])]['bandwidth'].mean()\n",
    "#fig, ax = plt.subplots(figsize=(16,4))\n",
    "#width = 0.35\n",
    "#plt.figure()\n",
    "for i, val in enumerate(size_ranges):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    rects1 = plt.bar(ranks_str, request_size[i], 0.35, label=str(i))\n",
    "    plt.show()\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Larger Request sizes have larger bandwidth. However as 4KB write dominates the application I/O we see small bandwidth overall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlapping of Compute and I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf.groupby('rank')['thread_id'].nunique().describe().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No additional threads means I/O is synchronous to compute. I.e. all I/O is unoverlapped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeline\n",
    "The timeline analysis shows how each rank performs I/O over the runtime of the applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step=10 # in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request Size Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "values = np.arange(0, math.ceil(job_time), time_step)\n",
    "values_int = range(len(values))\n",
    "values_str = []\n",
    "timeline_ts = [0]*len(values_int)\n",
    "prev = 0\n",
    "for i in values_int:\n",
    "    values_str.append(str(i))\n",
    "    contains = (io_ddf_read_write['tstart'] >=prev) & (io_ddf_read_write['tend'] <values[i])\n",
    "    timeline_ts[i] = io_ddf_read_write[contains]['size'].sum()/1024.0/1024.0\n",
    "    prev = i\n",
    "plt.bar(values_str[:4], timeline_ts[:4])\n",
    "plt.show()\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.bar(values_str[4:], timeline_ts[4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**Most of the I/O (20GB) is performed in first 40 seconds and rest 1GB happens in the rest of the time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "values = np.arange(0, math.ceil(job_time), time_step)\n",
    "values_int = range(len(values))\n",
    "timeline_ts = [0]*len(values_int)\n",
    "prev = 0\n",
    "values_str = []\n",
    "for i in values_int:\n",
    "    values_str.append(str(i))\n",
    "    contains = (io_ddf_read_write['tstart'] >=prev) & (io_ddf_read_write['tend'] <values[i])\n",
    "    timeline_ts[i] = io_ddf_read_write[contains]['duration'].sum()\n",
    "    prev = i\n",
    "plt.bar(values_str[:5], timeline_ts[:5])\n",
    "plt.show()\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.bar(values_str[5:], timeline_ts[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bandwidth Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "values = np.arange(0, math.ceil(job_time), time_step)\n",
    "values_int = range(len(values))\n",
    "timeline_ts = [0]*len(values_int)\n",
    "prev = 0\n",
    "values_str = []\n",
    "for i in values_int:\n",
    "    values_str.append(str(i))\n",
    "    contains = (io_ddf_read_write['tstart'] >=prev) & (io_ddf_read_write['tend'] <values[i])\n",
    "    timeline_ts[i] = io_ddf_read_write[contains]['bandwidth'].mean()/10.0\n",
    "    prev = i\n",
    "plt.bar(values_str[:5], timeline_ts[:5])\n",
    "plt.show()\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.bar(values_str[5:], timeline_ts[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This supports our previous observation as the bandwidth is the measure of I/O performance of the application.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bandwidth Timeline Per Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "selected_rank = [0, 4, 8, 12, 20]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "for rank in selected_rank:\n",
    "    io_df_rank = io_ddf_read_write[io_ddf_read_write['rank'] == rank]\n",
    "    values = np.arange(0, math.ceil(job_time), time_step)\n",
    "    values_int = range(len(values))\n",
    "    timeline_ts = [0]*len(values_int)\n",
    "    value_str = []\n",
    "    prev = 0\n",
    "    for i in values_int:\n",
    "        value_str.append(str(values[i]))\n",
    "        contains = (io_df_rank['tstart'] >=prev) & (io_df_rank['tend'] <values[i])\n",
    "        timeline_ts[i] = io_df_rank[contains]['bandwidth'].mean()\n",
    "        prev = i\n",
    "    print(\"rank {}\".format(rank))\n",
    "    plt.bar(value_str, timeline_ts)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**Most I/O happens in the first 40 sec and most bandwidth is achieved from PFS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Request Size Timeline per Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "selected_rank = [0, 4, 8, 12, 20]\n",
    "for rank in selected_rank:\n",
    "    io_df_rank = io_ddf_read_write[io_ddf_read_write['rank'] == rank]\n",
    "    values = np.arange(0, math.ceil(job_time), time_step)\n",
    "    values_int = range(len(values))\n",
    "    timeline_ts = [0]*len(values_int)\n",
    "    value_str = []\n",
    "    prev = 0\n",
    "    for i in values_int:\n",
    "        value_str.append(str(i))\n",
    "        contains = (io_df_rank['tstart'] >=prev) & (io_df_rank['tend'] <values[i])\n",
    "        timeline_ts[i] = io_df_rank[contains]['size'].sum()/1024.0/1024.0\n",
    "        prev = i\n",
    "    print(\"rank {}\".format(rank))\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.bar(value_str, timeline_ts)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "**Only rank 0 does I/O throughout the time. Rest perform read in first 40 seconds and perform computations.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find file which are independent or shared\n",
    "- Make all thread id start from 0 and unique across ranks\n",
    "- Group by filename nunique thread_id\n",
    "- Find all filename with nunique > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_index_series = io_ddf.groupby(['rank', 'thread_id'])['thread_id'].nunique().cumsum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_ddf['thread_index'] = 0\n",
    "for index,item in thread_index_series.iteritems():\n",
    "    condition = (io_ddf['rank'] == index[0]) & (io_ddf['thread_id'] == index[1])\n",
    "    io_ddf['thread_index'] = io_ddf['thread_index'].mask(condition , item - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = io_ddf['thread_index'].nunique().compute()\n",
    "print(\"We have {} threads across {} ranks\".format(threads, num_ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_series = io_ddf[io_ddf['filename'].str.contains('/p/gpfs1')].groupby(['filename'])['thread_index'].nunique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "independent_files = filename_series[filename_series == 1]\n",
    "print(\"{} files that are accessed by application by only one rank\".format(len(independent_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "outputs": [],
   "source": [
    "shared_files = filename_series[filename_series > 1]\n",
    "print(\"{} files that are accessed by application by more than one rank\".format(len(shared_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Finding"
    ]
   },
   "source": [
    "This application doesnt share files. That is it follows a File per process pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Flow\n",
    "We plot how different ranks in the job are accessing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "selected_indices = range(4)\n",
    "for selected_index in selected_indices:\n",
    "    selected_shared_file = shared_files.index[selected_index]\n",
    "    io_access_rank = io_ddf[io_ddf['filename'] == selected_shared_file].groupby(['rank','func_id'])['func_id'].count().compute()\n",
    "    dot.node(selected_shared_file)\n",
    "    for index,item in io_access_rank.iteritems():\n",
    "        rank = index[0]\n",
    "        func_id = index[1]\n",
    "        count = item\n",
    "        dot.node(str(rank))\n",
    "        dot.node(func_id)\n",
    "        dot.edge(str(rank),func_id)\n",
    "        if \"read\" in func_id:\n",
    "            dot.edge(selected_shared_file, func_id, label=str(count))\n",
    "        else:\n",
    "            dot.edge(func_id,selected_shared_file, label=str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "selected_indices = [0]\n",
    "for selected_index in selected_indices:\n",
    "    selected_file = independent_files.index[selected_index]\n",
    "    io_access_rank = io_ddf[io_ddf['filename'] == selected_file].groupby(['rank','func_id'])['func_id'].count().compute()\n",
    "    dot.node(selected_file)\n",
    "    for index,item in io_access_rank.iteritems():\n",
    "        rank = index[0]\n",
    "        func_id = index[1]\n",
    "        count = item\n",
    "        dot.node(str(rank))\n",
    "        dot.node(func_id)\n",
    "        dot.edge(str(rank),func_id)\n",
    "        if \"read\" in func_id:\n",
    "            dot.edge(selected_file, func_id, label=str(count))\n",
    "        else:\n",
    "            dot.edge(func_id,selected_file, label=str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Access Pattern\n",
    "- Calculate segment_index\n",
    "  - select file_ptr based on open flag\n",
    "  - update file_ptr based on operation\n",
    "  - do a cum_sum on file_ptr to calculate final file_ptr\n",
    "  - assign segment_index based on granularity (median transfer size)\n",
    "- isolate segment index into\n",
    "  - sequential flag if segment index is increasing\n",
    "  - consequitive flag if segment index is increasing and one after the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persist the current version of I/O dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "io_ddf = io_ddf.persist()\n",
    "result = wait(io_ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select files which have no seeks and those which have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_with_seek = io_ddf[io_ddf['func_id'].str.contains('seek') & io_ddf['filename'].str.contains('/p/gpfs')]['filename'].unique().compute()\n",
    "print(\"{} files have seek operations\".format(len(files_with_seek)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_with_seek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_without_seek = set(all_filenames) - set(files_with_seek)\n",
    "print(\"{} files have no seek operations and hence are sequential\".format(len(files_without_seek)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Per File Analysis\n",
    "- Total I/O amount\n",
    "- Total I/O time (average per process)\n",
    "- Average Bandwidth\n",
    "- I/O Request Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_file_size = io_ddf_read_write.groupby(['filename'])['size'].sum()\n",
    "per_file_size = per_file_size / 1024.0/1024.0\n",
    "per_file_size = per_file_size.sort_values(ascending=False)\n",
    "per_file_size.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_file_time = io_ddf_read_write.groupby(['filename'])['duration'].sum().sort_values(ascending=False)\n",
    "per_file_time.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_file_bw = io_ddf_read_write.groupby(['filename'])['bandwidth'].sum().sort_values(ascending=True)\n",
    "per_file_bw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "selected_indices = [0]\n",
    "for selected_index in selected_indices:\n",
    "    selected_file = per_file_size.index[selected_index]\n",
    "    io_access_rank = io_ddf[io_ddf['filename'] == selected_file].groupby(['rank','func_id'])['func_id'].count().compute()\n",
    "    dot.node(selected_file)\n",
    "    for index,item in io_access_rank.iteritems():\n",
    "        rank = index[0]\n",
    "        func_id = index[1]\n",
    "        count = item\n",
    "        if \"read\" in func_id or \"write\" in func_id:\n",
    "            dot.node(str(rank))\n",
    "            dot.node(func_id)\n",
    "            dot.edge(str(rank),func_id)\n",
    "            if \"read\" in func_id:\n",
    "                dot.edge(selected_file, func_id, label=str(count))\n",
    "            elif \"write\" in func_id:\n",
    "                dot.edge(func_id,selected_file, label=str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "selected_indices = [0]\n",
    "for selected_index in selected_indices:\n",
    "    selected_file = per_file_time.index[selected_index]\n",
    "    io_access_rank = io_ddf[io_ddf['filename'] == selected_file].groupby(['rank','func_id'])['func_id'].count().compute()\n",
    "    dot.node(selected_file)\n",
    "    for index,item in io_access_rank.iteritems():\n",
    "        rank = index[0]\n",
    "        func_id = index[1]\n",
    "        count = item\n",
    "        dot.node(str(rank))\n",
    "        dot.node(func_id)\n",
    "        dot.edge(str(rank),func_id)\n",
    "        if \"read\" in func_id:\n",
    "            dot.edge(selected_file, func_id, label=str(count))\n",
    "        else:\n",
    "            dot.edge(func_id,selected_file, label=str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot = graphviz.Digraph()\n",
    "selected_indices = range(5)\n",
    "for selected_index in selected_indices:\n",
    "    selected_file = per_file_bw.index[selected_index]\n",
    "    io_access_rank = io_ddf[io_ddf['filename'] == selected_file].groupby(['rank','func_id'])['func_id'].count().compute()\n",
    "    dot.node(selected_file)\n",
    "    for index,item in io_access_rank.iteritems():\n",
    "        rank = index[0]\n",
    "        func_id = index[1]\n",
    "        count = item\n",
    "        dot.node(str(rank))\n",
    "        dot.node(func_id)\n",
    "        dot.edge(str(rank),func_id)\n",
    "        if \"read\" in func_id:\n",
    "            dot.edge(selected_file, func_id, label=str(count))\n",
    "        else:\n",
    "            dot.edge(func_id,selected_file, label=str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_files = io_ddf_read_write[io_ddf_read_write['func_id'].str.contains('write')]['filename'].unique()\n",
    "read_files = io_ddf_read_write[io_ddf_read_write['func_id'].str.contains('read')]['filename'].unique()\n",
    "read_only_files = set(all_filenames) - set(write_files)\n",
    "write_only_files = set(all_filenames) - set(read_files)\n",
    "print(\"{} files are written into.\\n{} file are read from.\\n{} files are write-only.\\n{} file are read-only.\"\n",
    "      .format(len(write_files), len(read_files), len(write_only_files), len(read_only_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iopp",
   "language": "python",
   "name": "iopp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
